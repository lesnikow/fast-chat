# Results
# dpo vs dcpo using reference implementation for sft and dpo





## Reddit SHP, majority pref vs split cycle vs no training


Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                          score
model                                              turn        
shp_sc_data_dataset_dpo_loss_pythia28_model_32_... 1     2.5250
shp_maj_data_dataset_dpo_loss_pythia28_model_32... 1     2.2375
no_train_shp_maj_data_dataset_sft_loss_pythia28... 1     2.0500

########## Second turn ##########
                                                          score
model                                              turn        
shp_maj_data_dataset_dpo_loss_pythia28_model_32... 2     1.7625
shp_sc_data_dataset_dpo_loss_pythia28_model_32_... 2     1.7625
no_train_shp_maj_data_dataset_sft_loss_pythia28... 2     1.5500

########## Average ##########
                                                      score
model                                                      
shp_sc_data_dataset_dpo_loss_pythia28_model_32_...  2.14375
shp_maj_data_dataset_dpo_loss_pythia28_model_32...  2.00000
no_train_shp_maj_data_dataset_sft_loss_pythia28...  1.80000



Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl

                                                    win  loss  tie  win_rate  loss_rate win_rate_adjusted
model                                                                                                     
shp_sc_data_dataset_dpo_loss_pythia28_model_32_...  67    38  215  0.209375    0.11875     0.545312
shp_maj_data_dataset_dpo_loss_pythia28_model_32...  57    50  213  0.178125    0.15625     0.510938
no_train_shp_maj_data_dataset_sft_loss_pythia28...  38    74  208  0.118750    0.23125     0.443750














## Stanford human preference (SHP) a/k/a reddit, majority pref vs split-cycle, shp-maj vs shp-sc

### Eval mode: pairwise

model                                               win  loss  tie  win_rate  loss_rate  win_rate_adjusted
shp_maj_data_dataset_dpo_loss_pythia28_model_32...   27    26  107   0.16875    0.16250           0.503125                                                                                
shp_sc_data_dataset_dpo_loss_pythia28_model_32_...   26    27  107   0.16250    0.16875           0.496875    


### Eval mode: single score out of 10

########## First turn ##########
                                                          score
model                                              turn        
shp_sc_data_dataset_dpo_loss_pythia28_model_32_... 1     2.5250
shp_maj_data_dataset_dpo_loss_pythia28_model_32... 1     2.2375

########## Second turn ##########
                                                          score
model                                              turn        
shp_maj_data_dataset_dpo_loss_pythia28_model_32... 2     1.7625
shp_sc_data_dataset_dpo_loss_pythia28_model_32_... 2     1.7625

########## Average ##########
                                                      score
model                                                      
shp_sc_data_dataset_dpo_loss_pythia28_model_32_...  2.14375
shp_maj_data_dataset_dpo_loss_pythia28_model_32...  2.00000






## AV/RMP on haiku, gpt35, all

Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                                    win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                                     
av_11_gpt35_voters_dataset_dpo_loss_pythia28_mo...   38    26   96    0.2375     0.1625             0.5375
rmp_11_gpt35_voters_dataset_dpo_loss_pythia28_m...   26    38   96    0.1625     0.2375             0.4625

Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                          score
model                                              turn        
rmp_11_gpt35_voters_dataset_dpo_loss_pythia28_m... 1     2.3375
av_11_gpt35_voters_dataset_dpo_loss_pythia28_mo... 1     2.3000

########## Second turn ##########
                                                         score
model                                              turn       
rmp_11_gpt35_voters_dataset_dpo_loss_pythia28_m... 2     1.950
av_11_gpt35_voters_dataset_dpo_loss_pythia28_mo... 2     1.825

########## Average ##########
                                                      score
model                                                      
rmp_11_gpt35_voters_dataset_dpo_loss_pythia28_m...  2.14375
av_11_gpt35_voters_dataset_dpo_loss_pythia28_mo...  2.06250




Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                                    win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                                     
av_11_haiku_voters_dataset_dpo_loss_pythia28_mo...   40    26   93  0.251572   0.163522           0.544025
rmp_11_haiku_voters_dataset_dpo_loss_pythia28_m...   26    40   93  0.163522   0.251572           0.455975

Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                          score
model                                              turn        
av_11_haiku_voters_dataset_dpo_loss_pythia28_mo... 1     2.4250
rmp_11_haiku_voters_dataset_dpo_loss_pythia28_m... 1     1.9625

########## Second turn ##########
                                                          score
model                                              turn        
rmp_11_haiku_voters_dataset_dpo_loss_pythia28_m... 2     1.9375
av_11_haiku_voters_dataset_dpo_loss_pythia28_mo... 2     1.8875

########## Average ##########
                                                      score
model                                                      
av_11_haiku_voters_dataset_dpo_loss_pythia28_mo...  2.15625
rmp_11_haiku_voters_dataset_dpo_loss_pythia28_m...  1.95000




## DONE: Evals, RMP/MP and AV/RV pairwise comps

### MP / RMP
Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                         win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                          
rmp_llama3-8B_voters_128_max_new_tokens   32    32   96       0.2        0.2                0.5
mp_llama3-8B_voters_128_max_new_tokens    32    32   96       0.2        0.2                0.5


                                         win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                          
rmp_llama3-8B_voters_128_max_new_tokens   37    33   90   0.23125    0.20625             0.5125
mp_llama3-8B_voters_128_max_new_tokens    33    37   90   0.20625    0.23125             0.4875



### RV / AV
Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                        win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                         
av_llama3-8B_voters_128_max_new_tokens   42    22   96    0.2625     0.1375             0.5625
rv_llama3-8B_voters_128_max_new_tokens   22    42   96    0.1375     0.2625             0.4375


                                        win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                         
av_llama3-8B_voters_128_max_new_tokens   38    22   99  0.238994   0.138365           0.550314
rv_llama3-8B_voters_128_max_new_tokens   22    38   99  0.138365   0.238994           0.449686


## Llama3-8B 11 voters rmp vs av

Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                 score
model                                   turn          
av_llama3-8B_voters_128_max_new_tokens  1     2.500000
rmp_llama3-8B_voters_128_max_new_tokens 1     2.292683

########## Second turn ##########
                                                 score
model                                   turn          
rmp_llama3-8B_voters_128_max_new_tokens 2     1.865854
av_llama3-8B_voters_128_max_new_tokens  2     1.804878

########## Average ##########
                                            score
model                                            
av_llama3-8B_voters_128_max_new_tokens   2.152439
rmp_llama3-8B_voters_128_max_new_tokens  2.079268


Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                         win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                          
av_llama3-8B_voters_128_max_new_tokens    34    26  100    0.2125     0.1625              0.525
rmp_llama3-8B_voters_128_max_new_tokens   26    34  100    0.1625     0.2125              0.475


## Llama3-8B 11 mp vs rv aggregation

Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                score
model                                  turn          
rv_llama3-8B_voters_128_max_new_tokens 1     2.280488
mp_llama3-8B_voters_128_max_new_tokens 1     2.243902

########## Second turn ##########
                                                score
model                                  turn          
mp_llama3-8B_voters_128_max_new_tokens 2     1.682927
rv_llama3-8B_voters_128_max_new_tokens 2     1.670732

########## Average ##########
                                           score
model                                           
rv_llama3-8B_voters_128_max_new_tokens  1.975610
mp_llama3-8B_voters_128_max_new_tokens  1.963415


Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                        win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                         
mp_llama3-8B_voters_128_max_new_tokens   27    16  117   0.16875    0.10000           0.534375
rv_llama3-8B_voters_128_max_new_tokens   16    27  117   0.10000    0.16875           0.465625


## GPT 3.5 11 mp vs rv aggregation

Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                         score
model                                              turn       
rv_11_gpt35_voters_dataset_dpo_loss_pythia28_mo... 1     2.425
mp_11_gpt35_voters_dataset_dpo_loss_pythia28_mo... 1     2.325

########## Second turn ##########
                                                          score
model                                              turn        
mp_11_gpt35_voters_dataset_dpo_loss_pythia28_mo... 2     1.7375
rv_11_gpt35_voters_dataset_dpo_loss_pythia28_mo... 2     1.6875

########## Average ##########
                                                      score
model                                                      
rv_11_gpt35_voters_dataset_dpo_loss_pythia28_mo...  2.05625
mp_11_gpt35_voters_dataset_dpo_loss_pythia28_mo...  2.03125


Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                                    win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                                     
mp_11_gpt35_voters_dataset_dpo_loss_pythia28_mo...   22    16  122    0.1375     0.1000            0.51875
rv_11_gpt35_voters_dataset_dpo_loss_pythia28_mo...   16    22  122    0.1000     0.1375            0.48125




## Haiku 11 mp vs rv aggregation

Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                          score
model                                              turn        
mp_11_haiku_voters_dataset_dpo_loss_pythia28_mo... 1     2.4000
rv_11_haiku_voters_dataset_dpo_loss_pythia28_mo... 1     2.2125

########## Second turn ##########
                                                          score
model                                              turn        
mp_11_haiku_voters_dataset_dpo_loss_pythia28_mo... 2     1.6625
rv_11_haiku_voters_dataset_dpo_loss_pythia28_mo... 2     1.5750

########## Average ##########
                                                      score
model                                                      
mp_11_haiku_voters_dataset_dpo_loss_pythia28_mo...  2.03125
rv_11_haiku_voters_dataset_dpo_loss_pythia28_mo...  1.89375


Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                                    win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                                     
mp_11_haiku_voters_dataset_dpo_loss_pythia28_mo...   28    16  115  0.176101   0.100629           0.537736
rv_11_haiku_voters_dataset_dpo_loss_pythia28_mo...   16    28  115  0.100629   0.176101           0.462264




## 33 voter experiments
### Mode single
Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                            score
model                                              turn          
av_llama3-8B_voters_128_max_new_tokens             1     2.500000
hb_helpful_base_control_128_max_new_tokens         1     2.426829
rmp_llama3-8B_voters_128_max_new_tokens            1     2.292683
hb_helpful_base_control_512_max_new_tokens         1     2.287500
rv_llama3-8B_voters_128_max_new_tokens             1     2.280488
mp_llama3-8B_voters_128_max_new_tokens             1     2.243902
b_arm_original_dcpo_loss_128_max_new_tokens        1     2.200000
mp_3_x_11_voters_dataset_dpo_loss_pythia28_32_b... 1     2.200000
a_arm_original_dpo_loss_128_max_new_tokens         1     2.125000
av_llama3-8B_voters_512_max_new_tokens             1     2.125000
mp_llama3-8B_voters_512_max_new_tokens             1     2.062500
rmp_llama3-8B_voters_512_max_new_tokens            1     2.025000
rv_llama3-8B_voters_512_max_new_tokens             1     2.025000
rv_3_x_11_voters_dataset_dpo_loss_pythia28_32_b... 1     1.912500

########## Second turn ##########
                                                            score
model                                              turn          
rmp_llama3-8B_voters_512_max_new_tokens            2     1.887500
rmp_llama3-8B_voters_128_max_new_tokens            2     1.865854
av_llama3-8B_voters_128_max_new_tokens             2     1.804878
hb_helpful_base_control_128_max_new_tokens         2     1.780488
b_arm_original_dcpo_loss_128_max_new_tokens        2     1.712500
mp_llama3-8B_voters_128_max_new_tokens             2     1.682927
rv_llama3-8B_voters_128_max_new_tokens             2     1.670732
rv_llama3-8B_voters_512_max_new_tokens             2     1.662500
mp_llama3-8B_voters_512_max_new_tokens             2     1.650000
hb_helpful_base_control_512_max_new_tokens         2     1.575000
mp_3_x_11_voters_dataset_dpo_loss_pythia28_32_b... 2     1.550000
a_arm_original_dpo_loss_128_max_new_tokens         2     1.487500
av_llama3-8B_voters_512_max_new_tokens             2     1.450000
rv_3_x_11_voters_dataset_dpo_loss_pythia28_32_b... 2     1.437500

########## Average ##########
                                                       score
model                                                       
av_llama3-8B_voters_128_max_new_tokens              2.152439
hb_helpful_base_control_128_max_new_tokens          2.103659
rmp_llama3-8B_voters_128_max_new_tokens             2.079268
rv_llama3-8B_voters_128_max_new_tokens              1.975610
mp_llama3-8B_voters_128_max_new_tokens              1.963415
b_arm_original_dcpo_loss_128_max_new_tokens         1.956250
rmp_llama3-8B_voters_512_max_new_tokens             1.956250
hb_helpful_base_control_512_max_new_tokens          1.931250
mp_3_x_11_voters_dataset_dpo_loss_pythia28_32_b...  1.875000
mp_llama3-8B_voters_512_max_new_tokens              1.856250
rv_llama3-8B_voters_512_max_new_tokens              1.843750
a_arm_original_dpo_loss_128_max_new_tokens          1.806250
av_llama3-8B_voters_512_max_new_tokens              1.787500
rv_3_x_11_voters_dataset_dpo_loss_pythia28_32_b...  1.675000




### Mode pairwise-all

python3 show_result.py   --mode "pairwise-all"   --judge-model "gpt-4-turbo"   --model-list "${model_answers[@]}"
Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                                    win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                                     
mp_3_x_11_voters_dpo_loss_pythia28_32_batch_siz...   26    15  119   0.16250    0.09375           0.534375
rv_3_x_11_voters_dpo_loss_pythia28_32_batch_siz...   15    26  119   0.09375    0.16250           0.465625




## Five-arm experiment


python3 show_result.py   --mode single   --judge-model "gpt-4-turbo"
Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                 score
model                                   turn          
av_answers                              1     2.500000
hb_answers                              1     2.426829
rmp_answers                             1     2.292683
hb_answers_512_max_new_tokens           1     2.287500
rv_answers                              1     2.280488
mp_answers                              1     2.243902
b_dcpo_policy_answers_max_new_token_128 1     2.200000
a_dpo_model_answers_max_token_128       1     2.125000
av_answers_512_max_new_tokens           1     2.125000
mp_answers_512_max_new_tokens           1     2.062500
rmp_answers_512_max_new_tokens          1     2.025000
rv_answers_512_max_new_tokens           1     2.025000

########## Second turn ##########
                                                 score
model                                   turn          
rmp_answers_512_max_new_tokens          2     1.887500
rmp_answers                             2     1.865854
av_answers                              2     1.804878
hb_answers                              2     1.780488
b_dcpo_policy_answers_max_new_token_128 2     1.712500
mp_answers                              2     1.682927
rv_answers                              2     1.670732
rv_answers_512_max_new_tokens           2     1.662500
mp_answers_512_max_new_tokens           2     1.650000
hb_answers_512_max_new_tokens           2     1.575000
a_dpo_model_answers_max_token_128       2     1.487500
av_answers_512_max_new_tokens           2     1.450000

########## Average ##########
                                            score
model                                            
av_answers                               2.152439
hb_answers                               2.103659
rmp_answers                              2.079268
rv_answers                               1.975610
mp_answers                               1.963415
rmp_answers_512_max_new_tokens           1.956250
b_dcpo_policy_answers_max_new_token_128  1.956250
hb_answers_512_max_new_tokens            1.931250
mp_answers_512_max_new_tokens            1.856250
rv_answers_512_max_new_tokens            1.843750
a_dpo_model_answers_max_token_128        1.806250
av_answers_512_max_new_tokens            1.787500


python3 show_result.py   --mode single   --judge-model "gpt-4-turbo"
Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                                 score
model                                   turn
av_answers                              1     2.500000
hb_answers                              1     2.426829
rmp_answers                             1     2.292683
rv_answers                              1     2.280488
mp_answers                              1     2.243902
b_dcpo_policy_answers_max_new_token_128 1     2.200000
a_dpo_model_answers_max_token_128       1     2.125000

########## Second turn ##########
                                                 score
model                                   turn
rmp_answers                             2     1.865854
av_answers                              2     1.804878
hb_answers                              2     1.780488
b_dcpo_policy_answers_max_new_token_128 2     1.712500
mp_answers                              2     1.682927
rv_answers                              2     1.670732
a_dpo_model_answers_max_token_128       2     1.487500

########## Average ##########
                                            score
model
av_answers                               2.152439
hb_answers                               2.103659
rmp_answers                              2.079268
rv_answers                               1.975610
mp_answers                               1.963415
b_dcpo_policy_answers_max_new_token_128  1.956250
a_dpo_model_answers_max_token_128        1.806250







## Two-arm experiment

### Single
python show_result.py --input-file data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

Mode: single
Input file: data/mt_bench/model_judgment/gpt-4-turbo_single.jsonl

########## First turn ##########
                                              score
model                                   turn       
b_dcpo_policy_answers_max_new_token_128 1     2.200
a_dpo_model_answers_max_token_128       1     2.125

########## Second turn ##########
                                               score
model                                   turn        
b_dcpo_policy_answers_max_new_token_128 2     1.7125
a_dpo_model_answers_max_token_128       2     1.4875

########## Average ##########
                                           score
model                                           
b_dcpo_policy_answers_max_new_token_128  1.95625
a_dpo_model_answers_max_token_128        1.80625


### Pairwise
python show_result.py --mode pairwise-all --input-file data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl 

Mode: pairwise-all
Input file: data/mt_bench/model_judgment/gpt-4-turbo_pair.jsonl
                                         win  loss  tie  win_rate  loss_rate  win_rate_adjusted
model                                                                                          
b_dcpo_policy_answers_max_new_token_128   29    18  123  0.170588   0.105882           0.532353
a_dpo_model_answers_max_token_128         18    29  123  0.105882   0.170588           0.467647

Mode: single
Input file: data/mt_bench/model_judgment/gpt-4_single.jsonl

########## First turn ##########
                                           score
model                             turn          
gpt-4                             1     8.956250
claude-v1                         1     8.150000
gpt-3.5-turbo                     1     8.075000
claude-instant-v1                 1     7.800000
vicuna-33b-v1.3                   1     7.456250
wizardlm-30b                      1     7.131250
wizardlm-13b                      1     7.118750
oasst-sft-7-llama-30b             1     7.106250
Llama-2-13b-chat                  1     7.062500
tulu-30b                          1     7.018750
Llama-2-70b-chat                  1     6.987500
guanaco-33b                       1     6.881250
vicuna-13b-v1.3                   1     6.812500
guanaco-65b                       1     6.781250
palm-2-chat-bison-001             1     6.712500
vicuna-7b-v1.3                    1     6.693750
mpt-30b-chat                      1     6.675000
nous-hermes-13b                   1     6.431250
Llama-2-7b-chat                   1     6.412500
baize-v2-13b                      1     6.318750
gpt4all-13b-snoozy                1     6.075000
koala-13b                         1     6.075000
mpt-7b-chat                       1     5.850000
falcon-40b-instruct               1     5.812500
mpt-30b-instruct                  1     5.675000
h2ogpt-oasst-open-llama-13b       1     5.512500
chatglm-6b                        1     5.000000
alpaca-13b                        1     4.975000
oasst-sft-4-pythia-12b            1     4.975000
rwkv-4-raven-14b                  1     4.743750
dolly-v2-12b                      1     3.800000
fastchat-t5-3b                    1     3.393750
llama-13b                         1     3.262500
stablelm-tuned-alpha-7b           1     2.968750
a_dpo_model_answers_max_token_128 1     1.916667

########## Second turn ##########
                                           score
model                             turn          
gpt-4                             2     9.025000
claude-instant-v1                 2     8.012658
gpt-3.5-turbo                     2     7.812500
claude-v1                         2     7.650000
wizardlm-30b                      2     6.887500
vicuna-33b-v1.3                   2     6.787500
Llama-2-70b-chat                  2     6.725000
Llama-2-13b-chat                  2     6.237500
guanaco-33b                       2     6.175000
Llama-2-7b-chat                   2     6.125000
mpt-30b-chat                      2     6.112500
palm-2-chat-bison-001             2     6.087500
guanaco-65b                       2     6.037500
vicuna-13b-v1.3                   2     5.962500
tulu-30b                          2     5.850000
oasst-sft-7-llama-30b             2     5.712500
wizardlm-13b                      2     5.587500
vicuna-7b-v1.3                    2     5.300000
baize-v2-13b                      2     5.181250
mpt-7b-chat                       2     5.063291
gpt4all-13b-snoozy                2     4.822785
mpt-30b-instruct                  2     4.762500
nous-hermes-13b                   2     4.664557
koala-13b                         2     4.625000
falcon-40b-instruct               2     4.525000
alpaca-13b                        2     4.087500
chatglm-6b                        2     4.000000
h2ogpt-oasst-open-llama-13b       2     3.737500
oasst-sft-4-pythia-12b            2     3.662500
rwkv-4-raven-14b                  2     3.225000
dolly-v2-12b                      2     2.750000
fastchat-t5-3b                    2     2.687500
stablelm-tuned-alpha-7b           2     2.537500
llama-13b                         2     1.950000
a_dpo_model_answers_max_token_128 2     1.083333

########## Average ##########
                                      score
model                                      
gpt-4                              8.990625
gpt-3.5-turbo                      7.943750
claude-instant-v1                  7.905660
claude-v1                          7.900000
vicuna-33b-v1.3                    7.121875
wizardlm-30b                       7.009375
Llama-2-70b-chat                   6.856250
Llama-2-13b-chat                   6.650000
guanaco-33b                        6.528125
tulu-30b                           6.434375
guanaco-65b                        6.409375
oasst-sft-7-llama-30b              6.409375
palm-2-chat-bison-001              6.400000
mpt-30b-chat                       6.393750
vicuna-13b-v1.3                    6.387500
wizardlm-13b                       6.353125
Llama-2-7b-chat                    6.268750
vicuna-7b-v1.3                     5.996875
baize-v2-13b                       5.750000
nous-hermes-13b                    5.553459
mpt-7b-chat                        5.459119
gpt4all-13b-snoozy                 5.452830
koala-13b                          5.350000
mpt-30b-instruct                   5.218750
falcon-40b-instruct                5.168750
h2ogpt-oasst-open-llama-13b        4.625000
alpaca-13b                         4.531250
chatglm-6b                         4.500000
oasst-sft-4-pythia-12b             4.318750
rwkv-4-raven-14b                   3.984375
dolly-v2-12b                       3.275000
fastchat-t5-3b                     3.040625
stablelm-tuned-alpha-7b            2.753125
llama-13b                          2.606250
a_dpo_model_answers_max_token_128  1.500000

-------------------------------------------


